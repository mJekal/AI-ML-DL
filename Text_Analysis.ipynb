{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 텍스트 분석\n",
        "\n",
        "- NLP(자연어 처리) : 인간의 언어를 이해하고 해석하는데 더 중점을 두고 기술이 발전해 옴, 텍스트 분석을 향상하게 하는 기반 기술\n",
        "\n",
        "- TA(텍스트 분석) : 비정형 데이터에서 모델을 수립하고 의미있는 정보를 추출, 비정형 데이터인 텍스트를 분석\n",
        "\n",
        "- 머신러닝 알고리즘은 숫자형의 피처기반 데이터만 입력받을 수 있기 때문에 ‘비정형 텍스트 데이터를 어떻게 피처 형태로 추출하고 추출된 피처에 의미있는 값을 부여하는가’ 하는 것이 매우 중요한 요소\n",
        "\n",
        "### 텍스트 분석 주요 영역\n",
        "\n",
        "- 텍스트 분류\n",
        "  - 문서가 특정 분류 또는 카테고리에 속하는 것을 예측하는 기법을 통칭.\n",
        "  - 예시 : 특정 신문 기사 내용이 연애/정치/사회/문화 중 어떤 카테고리에 속하는지 자동으로 분류하거나 스팸 메일 검출 같은 프로그램.\n",
        "  - 지도학습을 적용.\n",
        "- 감성 분석\n",
        "  - 텍스트에서 나타나는 감정/판단/믿음/의견/기분 등의 주관적인 요소를 분석하는 기법을 총칭.\n",
        "  - 예시 : 소셜 미디어 감정 분석, 영화나 제품에 대한 긍정 또는 리뷰, 여론조사 의견 분석 등의 다양한 영역에서 활용.\n",
        "  - 지도학습 및 비지도학습 적용.\n",
        "- 텍스트 요약\n",
        "  - 텍스트 내에서 중요한 주제나 중심 사상을 추출하는 기법.\n",
        "  - 예시 : 토픽 모델링(Topic Modeling)\n",
        "- 텍스트 군집화와 유사도 측정\n",
        "  - 비슷한 유형의 문서에 대해 군집화를 수행하는 기법.\n",
        "  - 예시 : 텍스트 분류를 비지도학습으로 수행하는 방법의 일환으로 사용\n",
        "  - 문서들간의 유사도 측정해 비슷한 문서끼리 모을 수 있는 방법.\n",
        "\n",
        "### 텍스트 분석 프로세스\n",
        "\n",
        "- 텍스트 전처리 : 텍스트를 피처로 만들기 전 클렌징 작업, 토큰화 작업, 어근 추출 등의 텍스트 정규화 작업을 통칭\n",
        "- 피처 벡터화/추출 : 전처리된 텍스트에서 피처를 추출하고 벡터값 할당. 대표적인 방법 BOW, Word2Vec\n",
        "- ML 모델 수립 및 학습/예측/평가 : 피처 벡터화된 데이터 세트에 ML 모델 적용해 학습/예측/평가 수행\n",
        "\n",
        "### 패키지\n",
        "- NLTK : 파이썬의 가장 대표적인 NLP 패키지. 수행 속도 측면에서 아쉬움.\n",
        "- Gensim : 토픽 모델링 분야에서 가장 두각을 나타내는 패키지. Word2Vec 구현. 가장 많이 사용\n",
        "- SpaCy : 뛰어난 수행 성능\n",
        "\n",
        "### 텍스트 전처리 - 텍스트 정규화\n",
        "\n",
        "- 클렌징(Cleansing) : 불필요한 문자, 기호 등을 사전에 제거 (ex. HTML, XML 태그나 특정기호)\n",
        "- 토큰화(Tokenization) : 문장 토큰화, 단어 토큰화, n-gram(연속된 n개의 단어를 하나의 토큰화 단위로 분리해 내는 것)\n",
        "  - n-gram 예시 : Agent Smith knocks the door를 2-gram으로 만들면 (Agent, Smith),(Smith,knocks),(knocks,the),(the,door)와 같이 연속적으로 2개의 단어들을 순차적으로 이동하면서 토큰화\n",
        "- 필터링/스톱 워드 제거/철자 수정\n",
        "- Stemming / Lemmatization : 어근 추출, Lemmatizationㅇ Stemming보다 정교하고 의미론적 기반에서 단어 원형을 찾아줌\n",
        "\n"
      ],
      "metadata": {
        "id": "z3SIXaxoDhtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk import ngrams\n",
        "import nltk\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SasDIy40GAKo",
        "outputId": "8e4d2f24-9ef6-48ee-a30b-400e0dde78a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Tokenization"
      ],
      "metadata": {
        "id": "aHaIp_9TI1GL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문장 토큰화 / 단어 토큰화"
      ],
      "metadata": {
        "id": "bbH3uT1umA8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_sample = 'The Matrix is everywhere its all around us, here even in this room.  \\\n",
        "              You can see it out your window or on your television. \\\n",
        "               You feel it when you go to work, or go to church or pay your taxes.'\n",
        "sentences = sent_tokenize(text=text_sample)\n",
        "print(type(sentences),len(sentences))\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSuAifPeI0br",
        "outputId": "d9418606-8f28-442b-b4ec-1b4f3424b1d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 3\n",
            "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The Matrix is everywhere its all around us, here even in this room.\"\n",
        "words = word_tokenize(sentence)\n",
        "print(type(words), len(words))\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqLK5BZIJ6DH",
        "outputId": "60d59399-5018-416e-eef0-936249d97ee3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 15\n",
            "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(text):\n",
        "    # 문장별로 분리 토큰\n",
        "    sentences = sent_tokenize(text)\n",
        "    # 분리된 문장별 단어 토큰화\n",
        "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
        "    return word_tokens"
      ],
      "metadata": {
        "id": "kKe63KQuJ7zc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens = tokenize_text(text_sample)\n",
        "print(type(word_tokens),len(word_tokens))\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goOGgcvSKGv3",
        "outputId": "d99bd101-a133-4eca-a81a-7ef98f194af5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 3\n",
            "[['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.'], ['You', 'can', 'see', 'it', 'out', 'your', 'window', 'or', 'on', 'your', 'television', '.'], ['You', 'feel', 'it', 'when', 'you', 'go', 'to', 'work', ',', 'or', 'go', 'to', 'church', 'or', 'pay', 'your', 'taxes', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### n-gram"
      ],
      "metadata": {
        "id": "lXJS0qv0mGgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The Matrix is everywhere its all around us, here even in this room.\"\n",
        "words = word_tokenize(sentence)\n",
        "\n",
        "all_ngrams = ngrams(words, 2)\n",
        "ngrams = [ngram for ngram in all_ngrams]\n",
        "print(ngrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iLQBIOpKJe3",
        "outputId": "cc0b6791-1b06-4fed-d08d-74a8b5880ca2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'Matrix'), ('Matrix', 'is'), ('is', 'everywhere'), ('everywhere', 'its'), ('its', 'all'), ('all', 'around'), ('around', 'us'), ('us', ','), (',', 'here'), ('here', 'even'), ('even', 'in'), ('in', 'this'), ('this', 'room'), ('room', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stopwords 제거"
      ],
      "metadata": {
        "id": "On2Zq6a5mKnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('영어 stop words 갯수:',len(nltk.corpus.stopwords.words('english')))\n",
        "print(nltk.corpus.stopwords.words('english')[:40])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1milt0eeKq-q",
        "outputId": "2dac2f0c-ba25-4dfd-f242-d925f62d1aab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 stop words 갯수: 179\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "all_tokens = []\n",
        "\n",
        "for sentence in word_tokens:\n",
        "    filtered_words=[]\n",
        "    for word in sentence:\n",
        "        word = word.lower()\n",
        "        if word not in stopwords:\n",
        "            filtered_words.append(word)\n",
        "    all_tokens.append(filtered_words)\n",
        "\n",
        "print(all_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcfBcMy-KsXn",
        "outputId": "3af1c651-5bb0-4d24-ff86-5d402491025d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.'], ['see', 'window', 'television', '.'], ['feel', 'go', 'work', ',', 'go', 'church', 'pay', 'taxes', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stemming / Lemmatization\n",
        "\n"
      ],
      "metadata": {
        "id": "FWxpTk0YmOfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = LancasterStemmer()\n",
        "\n",
        "print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))\n",
        "print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))\n",
        "print(stemmer.stem('happier'),stemmer.stem('happiest'))\n",
        "print(stemmer.stem('fancier'),stemmer.stem('fanciest'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv7OPj40LpAT",
        "outputId": "431e036e-a8dd-4b4d-f88d-6cd76c5c394f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "work work work\n",
            "amus amus amus\n",
            "happy happiest\n",
            "fant fanciest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemma = WordNetLemmatizer()\n",
        "print(lemma.lemmatize('amusing','v'),lemma.lemmatize('amuses','v'),lemma.lemmatize('amused','v'))\n",
        "print(lemma.lemmatize('happier','a'),lemma.lemmatize('happiest','a'))\n",
        "print(lemma.lemmatize('fancier','a'),lemma.lemmatize('fanciest','a'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVdHxTJyLvR-",
        "outputId": "7417b75c-02b4-44cb-eed1-8231e2b65102"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amuse amuse amuse\n",
            "happy happy\n",
            "fancy fancy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag of Words - BOW"
      ],
      "metadata": {
        "id": "w_GiP-RhmUXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_sample_01 = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
        "                  You can see it out your window or on your television. \\\n",
        "                  You feel it when you go to work, or go to church or pay your taxes.'\n",
        "text_sample_02 = 'You take the blue pill and the story ends.  You wake in your bed and you believe whatever you want to believe\\\n",
        "                  You take the red pill and you stay in Wonderland and I show you how deep the rabbit-hole goes.'\n",
        "text=[]\n",
        "text.append(text_sample_01); text.append(text_sample_02)\n",
        "print(text,\"\\n\", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKbXultoMCtZ",
        "outputId": "4b32a755-f8fa-47a9-97ad-5042de5bfbd9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The Matrix is everywhere its all around us, here even in this room.                   You can see it out your window or on your television.                   You feel it when you go to work, or go to church or pay your taxes.', 'You take the blue pill and the story ends.  You wake in your bed and you believe whatever you want to believe                  You take the red pill and you stay in Wonderland and I show you how deep the rabbit-hole goes.'] \n",
            " 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 피처 벡터화/추출 - BOW(Bag of Words)\n",
        "### Bag of words\n",
        "- 문서가 가지는 모든 단어의 문맥이나 순서를 무시하고 단어에 대해 빈도 값을 부여해 피처 값을 추출하는 모델\n",
        "- 장점 : 쉽고 빠른 구축\n",
        "- 단점:\n",
        "    - 문맥 의미 반영 부족 : 단어의 문맥, 순서를 반영하지 않기 때문. n_gram 기법을 활용할 수 있지만 제한적임\n",
        "    - 희소 행렬 문제 : 매우 많은 문서에 단어의 개수는 수만~수십만개 인 것에 비해 하나의 문서에 있는 단어는 이 중 극히 일부분임. 따라서 대규모의 칼럼으로 구성된 행렬에서 대부분의 값이 0으로 채워져 ML 알고리즘의 수행시간,예측성능을 떨어트림\n",
        "\n",
        "### BOW 피처 벡터화\n",
        "- 모든 문서에서 모든 단어를 칼럼형태로 나열하고 각 문서에서 해당 단어의 횟수, 정규화된 빈도 값으로 데이터 세트 모델로 변경하는 것\n",
        "- 예시 : 문서 개수 M , 단어 개수 N → M x N 의 데이터 세트 행렬 구성\n",
        "- 카운트 기반 벡터화 : 해당 단어가 나타나는 횟수 기반\n",
        "- TF-IDF : 자주 나타나는 단어에 높은 가중치를 주되, 모든 문서에서 전반적으로 자주 나타나는 단어에 대해서는 패널티 부여\n",
        "\n",
        "### 사이킷런의 Count 및 TF-IDF 벡터화 구현 : CountVectorizer, TfidfVectorizer\n",
        "\n",
        "- countvectorizer 은 카운트 기반의 피처 벡터화 방법, 텍스트 전처리 수행 후 fit(), transform()을 통해 피처 벡터화된 객체 반환\n",
        "- 사전 데이터 가공 : 모든 문자를 소문자로 변환하는 등의 사전 작업 수행\n",
        "- 토큰화 : Default 는 단어 기준, n_gram_range 를 사용하여 토큰화 수행\n",
        "- 텍스트 정규화 : Stop words 필터링만 수행, Stemmer, lemmatize를 수행하기 위해서는 tokenizer 파라미터에 해당 함수 적용\n",
        "- 피처 벡터화 : max_df, min_df, max_features 등의 파라미터를 반영하여 token 된 단어들을 피처 추출한 후 벡터화 진행"
      ],
      "metadata": {
        "id": "_AAoMZLpmeWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnt_vect = CountVectorizer()\n",
        "cnt_vect.fit(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "lxPAdTWpjAXX",
        "outputId": "0a6261c0-51a6-4de8-ade0-b3996cf4ed26"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ftr_vect = cnt_vect.transform(text)"
      ],
      "metadata": {
        "id": "JFwm0kXkjC00"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(ftr_vect), ftr_vect.shape)\n",
        "print(ftr_vect)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKRiYDWxjF-5",
        "outputId": "77feb358-fade-4561-8b39-27468623f376"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'> (2, 51)\n",
            "  (0, 0)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 10)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 12)\t1\n",
            "  (0, 13)\t2\n",
            "  (0, 15)\t1\n",
            "  (0, 18)\t1\n",
            "  (0, 19)\t1\n",
            "  (0, 20)\t2\n",
            "  (0, 21)\t1\n",
            "  (0, 22)\t1\n",
            "  (0, 23)\t1\n",
            "  (0, 24)\t3\n",
            "  (0, 25)\t1\n",
            "  (0, 26)\t1\n",
            "  (0, 30)\t1\n",
            "  (0, 31)\t1\n",
            "  (0, 36)\t1\n",
            "  (0, 37)\t1\n",
            "  (0, 38)\t1\n",
            "  (0, 39)\t1\n",
            "  (0, 40)\t2\n",
            "  :\t:\n",
            "  (1, 1)\t4\n",
            "  (1, 3)\t1\n",
            "  (1, 4)\t2\n",
            "  (1, 5)\t1\n",
            "  (1, 8)\t1\n",
            "  (1, 9)\t1\n",
            "  (1, 14)\t1\n",
            "  (1, 16)\t1\n",
            "  (1, 17)\t1\n",
            "  (1, 18)\t2\n",
            "  (1, 27)\t2\n",
            "  (1, 28)\t1\n",
            "  (1, 29)\t1\n",
            "  (1, 32)\t1\n",
            "  (1, 33)\t1\n",
            "  (1, 34)\t1\n",
            "  (1, 35)\t2\n",
            "  (1, 38)\t4\n",
            "  (1, 40)\t1\n",
            "  (1, 42)\t1\n",
            "  (1, 43)\t1\n",
            "  (1, 44)\t1\n",
            "  (1, 47)\t1\n",
            "  (1, 49)\t7\n",
            "  (1, 50)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cnt_vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd8jdpLVjKdI",
        "outputId": "d95a537f-e1b6-43f1-bd6c-82704169d5f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 38, 'matrix': 22, 'is': 19, 'everywhere': 11, 'its': 21, 'all': 0, 'around': 2, 'us': 41, 'here': 15, 'even': 10, 'in': 18, 'this': 39, 'room': 30, 'you': 49, 'can': 6, 'see': 31, 'it': 20, 'out': 25, 'your': 50, 'window': 46, 'or': 24, 'on': 23, 'television': 37, 'feel': 12, 'when': 45, 'go': 13, 'to': 40, 'work': 48, 'church': 7, 'pay': 26, 'taxes': 36, 'take': 35, 'blue': 5, 'pill': 27, 'and': 1, 'story': 34, 'ends': 9, 'wake': 42, 'bed': 3, 'believe': 4, 'whatever': 44, 'want': 43, 'red': 29, 'stay': 33, 'wonderland': 47, 'show': 32, 'how': 17, 'deep': 8, 'rabbit': 28, 'hole': 16, 'goes': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnt_vect = CountVectorizer(max_features=5, stop_words='english')\n",
        "cnt_vect.fit(text)\n",
        "ftr_vect = cnt_vect.transform(text)\n",
        "print(ftr_vect)\n",
        "print(type(ftr_vect),ftr_vect.shape)\n",
        "print(cnt_vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcymL4aomjOx",
        "outputId": "c4d80724-4c4d-46dd-923f-abd0ba4bdb99"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 4)\t1\n",
            "  (1, 0)\t2\n",
            "  (1, 1)\t2\n",
            "  (1, 2)\t1\n",
            "  (1, 3)\t1\n",
            "<class 'scipy.sparse._csr.csr_matrix'> (2, 5)\n",
            "{'window': 4, 'pill': 1, 'wake': 2, 'believe': 0, 'want': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnt_vect = CountVectorizer(ngram_range=(1,3))\n",
        "cnt_vect.fit(text)\n",
        "ftr_vect = cnt_vect.transform(text)\n",
        "print(type(ftr_vect), ftr_vect.shape)\n",
        "print(cnt_vect.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIhd_xC2nJKO",
        "outputId": "c44285b1-a05a-4137-9990-63becdf0a350"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'> (2, 201)\n",
            "{'the': 129, 'matrix': 77, 'is': 66, 'everywhere': 40, 'its': 74, 'all': 0, 'around': 11, 'us': 150, 'here': 51, 'even': 37, 'in': 59, 'this': 140, 'room': 106, 'you': 174, 'can': 25, 'see': 109, 'it': 69, 'out': 90, 'your': 193, 'window': 165, 'or': 83, 'on': 80, 'television': 126, 'feel': 43, 'when': 162, 'go': 46, 'to': 143, 'work': 171, 'church': 28, 'pay': 93, 'taxes': 125, 'the matrix': 132, 'matrix is': 78, 'is everywhere': 67, 'everywhere its': 41, 'its all': 75, 'all around': 1, 'around us': 12, 'us here': 151, 'here even': 52, 'even in': 38, 'in this': 60, 'this room': 141, 'room you': 107, 'you can': 177, 'can see': 26, 'see it': 110, 'it out': 70, 'out your': 91, 'your window': 199, 'window or': 166, 'or on': 86, 'on your': 81, 'your television': 197, 'television you': 127, 'you feel': 179, 'feel it': 44, 'it when': 72, 'when you': 163, 'you go': 181, 'go to': 47, 'to work': 148, 'work or': 172, 'or go': 84, 'to church': 146, 'church or': 29, 'or pay': 88, 'pay your': 94, 'your taxes': 196, 'the matrix is': 133, 'matrix is everywhere': 79, 'is everywhere its': 68, 'everywhere its all': 42, 'its all around': 76, 'all around us': 2, 'around us here': 13, 'us here even': 152, 'here even in': 53, 'even in this': 39, 'in this room': 61, 'this room you': 142, 'room you can': 108, 'you can see': 178, 'can see it': 27, 'see it out': 111, 'it out your': 71, 'out your window': 92, 'your window or': 200, 'window or on': 167, 'or on your': 87, 'on your television': 82, 'your television you': 198, 'television you feel': 128, 'you feel it': 180, 'feel it when': 45, 'it when you': 73, 'when you go': 164, 'you go to': 182, 'go to work': 49, 'to work or': 149, 'work or go': 173, 'or go to': 85, 'go to church': 48, 'to church or': 147, 'church or pay': 30, 'or pay your': 89, 'pay your taxes': 95, 'take': 121, 'blue': 22, 'pill': 96, 'and': 3, 'story': 118, 'ends': 34, 'wake': 153, 'bed': 14, 'believe': 17, 'whatever': 159, 'want': 156, 'red': 103, 'stay': 115, 'wonderland': 168, 'show': 112, 'how': 56, 'deep': 31, 'rabbit': 100, 'hole': 54, 'goes': 50, 'you take': 187, 'take the': 122, 'the blue': 130, 'blue pill': 23, 'pill and': 97, 'and the': 6, 'the story': 138, 'story ends': 119, 'ends you': 35, 'you wake': 189, 'wake in': 154, 'in your': 64, 'your bed': 194, 'bed and': 15, 'and you': 8, 'you believe': 175, 'believe whatever': 18, 'whatever you': 160, 'you want': 191, 'want to': 157, 'to believe': 144, 'believe you': 20, 'the red': 136, 'red pill': 104, 'you stay': 185, 'stay in': 116, 'in wonderland': 62, 'wonderland and': 169, 'and show': 4, 'show you': 113, 'you how': 183, 'how deep': 57, 'deep the': 32, 'the rabbit': 134, 'rabbit hole': 101, 'hole goes': 55, 'you take the': 188, 'take the blue': 123, 'the blue pill': 131, 'blue pill and': 24, 'pill and the': 98, 'and the story': 7, 'the story ends': 139, 'story ends you': 120, 'ends you wake': 36, 'you wake in': 190, 'wake in your': 155, 'in your bed': 65, 'your bed and': 195, 'bed and you': 16, 'and you believe': 9, 'you believe whatever': 176, 'believe whatever you': 19, 'whatever you want': 161, 'you want to': 192, 'want to believe': 158, 'to believe you': 145, 'believe you take': 21, 'take the red': 124, 'the red pill': 137, 'red pill and': 105, 'pill and you': 99, 'and you stay': 10, 'you stay in': 186, 'stay in wonderland': 117, 'in wonderland and': 63, 'wonderland and show': 170, 'and show you': 5, 'show you how': 114, 'you how deep': 184, 'how deep the': 58, 'deep the rabbit': 33, 'the rabbit hole': 135, 'rabbit hole goes': 102}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 희소행렬 - COO 형식\n",
        "\n",
        "- 0이 아닌 데이터만 별도의 배열에 저장하고, 그 데이터가 가르키는 행, 열 위치를 별도의 배열로 저장하는 방식\n",
        "- 희소행렬 변환은 scipy의 coo_matrix 클래스를 이용\n",
        "\n",
        "### 희소행렬-CSR 형식\n",
        "\n",
        "- COO 형식이 반복적인 행,열 위치 데이터를 사용해야하는 문제점 해결\n",
        "- 행 위치 배열 대신 행 위치 배열의 고유값 시작 인덱스 배열 + 총 항목 개수 배열로 변환 → COO 보다 메모리가 적게들고 빠른 연산 가능\n",
        "- 희소행렬 변환은 scipy 의 csr_matrix 클래스를 이용\n",
        "- 사이킷런의 CountVectorizer, TfidfVectorizer 클래스로 변환된 피처 벡터화 행렬은 모두 CSR 형태의 희소 행렬"
      ],
      "metadata": {
        "id": "6J-zdBInmaQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense = np.array( [ [ 3, 0, 1 ],\n",
        "                    [0, 2, 0 ] ] )"
      ],
      "metadata": {
        "id": "cCCaJ7ZIuYk8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([3,1,2])\n",
        "row_pos = np.array([0,0,1])\n",
        "col_pos = np.array([0,2,1])\n",
        "sparse_coo = sparse.coo_matrix((data, (row_pos,col_pos)))"
      ],
      "metadata": {
        "id": "xFmztISVubzU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(sparse_coo))\n",
        "print(sparse_coo)\n",
        "dense01=sparse_coo.toarray()\n",
        "print(type(dense01),\"\\n\", dense01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0haqiYXFuj-A",
        "outputId": "810043c2-4b15-42b4-e30d-3561ecb7d9cd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._coo.coo_matrix'>\n",
            "  (0, 0)\t3\n",
            "  (0, 2)\t1\n",
            "  (1, 1)\t2\n",
            "<class 'numpy.ndarray'> \n",
            " [[3 0 1]\n",
            " [0 2 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense2 = np.array([[0,0,1,0,0,5],\n",
        "             [1,4,0,3,2,5],\n",
        "             [0,6,0,3,0,0],\n",
        "             [2,0,0,0,0,0],\n",
        "             [0,0,0,7,0,8],\n",
        "             [1,0,0,0,0,0]])\n",
        "\n",
        "data2 = np.array([1, 5, 1, 4, 3, 2, 5, 6, 3, 2, 7, 8, 1])\n",
        "\n",
        "row_pos = np.array([0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 4, 4, 5])\n",
        "col_pos = np.array([2, 5, 0, 1, 3, 4, 5, 1, 3, 0, 3, 5, 0])\n",
        "\n",
        "sparse_coo = sparse.coo_matrix((data2, (row_pos,col_pos)))\n",
        "\n",
        "row_pos_ind = np.array([0, 2, 7, 9, 10, 12, 13])\n",
        "\n",
        "sparse_csr = sparse.csr_matrix((data2, col_pos, row_pos_ind))\n",
        "\n",
        "print(sparse_coo.toarray())\n",
        "print(sparse_csr.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLiZrScTutRm",
        "outputId": "b18f5a9d-c171-45f4-8304-933fe5bcd0bd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 0 0 5]\n",
            " [1 4 0 3 2 5]\n",
            " [0 6 0 3 0 0]\n",
            " [2 0 0 0 0 0]\n",
            " [0 0 0 7 0 8]\n",
            " [1 0 0 0 0 0]]\n",
            "[[0 0 1 0 0 5]\n",
            " [1 4 0 3 2 5]\n",
            " [0 6 0 3 0 0]\n",
            " [2 0 0 0 0 0]\n",
            " [0 0 0 7 0 8]\n",
            " [1 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sparse_csr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVlZjmYBu2yg",
        "outputId": "abacf2d1-4120-4f1a-9c13-be1c65946498"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 2)\t1\n",
            "  (0, 5)\t5\n",
            "  (1, 0)\t1\n",
            "  (1, 1)\t4\n",
            "  (1, 3)\t3\n",
            "  (1, 4)\t2\n",
            "  (1, 5)\t5\n",
            "  (2, 1)\t6\n",
            "  (2, 3)\t3\n",
            "  (3, 0)\t2\n",
            "  (4, 3)\t7\n",
            "  (4, 5)\t8\n",
            "  (5, 0)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense3 = np.array([[0,0,1,0,0,5],\n",
        "             [1,4,0,3,2,5],\n",
        "             [0,6,0,3,0,0],\n",
        "             [2,0,0,0,0,0],\n",
        "             [0,0,0,7,0,8],\n",
        "             [1,0,0,0,0,0]])\n",
        "\n",
        "coo = sparse.coo_matrix(dense3)\n",
        "csr = sparse.csr_matrix(dense3)"
      ],
      "metadata": {
        "id": "kPrNHGrmu6Tq"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}