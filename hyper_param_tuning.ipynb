{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPE6cjGUPL9WvlEElbQkb4V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mJekal/PyTorch_study/blob/main/hyper_param_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bayesian-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAE0_5NYDAtW",
        "outputId": "040c36de-aa39-4c46-9b44-b03a93029d5d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.10/dist-packages (1.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.2.2)\n",
            "Requirement already satisfied: colorama>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (0.4.6)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "%matplotlib inline\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from lightgbm import LGBMClassifier"
      ],
      "metadata": {
        "id": "kzJvFUWEDEQT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bayesian_params = {\n",
        "    'max_depth': (6, 16),\n",
        "    'num_leaves': (24, 64),\n",
        "    'min_child_samples': (10, 200),\n",
        "    'min_child_weight':(1, 50),\n",
        "    'subsample':(0.5, 1.0),\n",
        "    'colsample_bytree': (0.5, 1.0),\n",
        "    'max_bin':(10, 500),\n",
        "    'reg_lambda':(0.001, 10),\n",
        "    'reg_alpha': (0.01, 50)\n",
        "}"
      ],
      "metadata": {
        "id": "tbE7SCt4DGUt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lgb_roc_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample,\n",
        "                colsample_bytree,max_bin, reg_lambda, reg_alpha):\n",
        "    params = {\n",
        "        \"n_estimators\":500, \"learning_rate\":0.02,\n",
        "        'max_depth': int(round(max_depth)),\n",
        "        'num_leaves': int(round(num_leaves)),\n",
        "        'min_child_samples': int(round(min_child_samples)),\n",
        "        'min_child_weight': int(round(min_child_weight)),\n",
        "        'subsample': max(min(subsample, 1), 0),\n",
        "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
        "        'max_bin':  max(int(round(max_bin)),10),\n",
        "        'reg_lambda': max(reg_lambda,0),\n",
        "        'reg_alpha': max(reg_alpha, 0)\n",
        "    }\n",
        "    lgb_model = LGBMClassifier(**params)\n",
        "    lgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc',)\n",
        "    valid_proba = lgb_model.predict_proba(valid_x)[:, 1]\n",
        "    roc_auc = roc_auc_score(valid_y, valid_proba)\n",
        "\n",
        "    return roc_auc"
      ],
      "metadata": {
        "id": "Lmv2CPvjDLwt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbBO = BayesianOptimization(lgb_roc_eval,bayesian_params , random_state=0)\n",
        "lgbBO.maximize(init_points=5, n_iter=25)"
      ],
      "metadata": {
        "id": "pP4VchRKTLAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbBO.res"
      ],
      "metadata": {
        "id": "7Pc-HD9zTWf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_list = []\n",
        "for result in lgbBO.res:\n",
        "    target = result['target']\n",
        "    target_list.append(target)\n",
        "print(target_list)\n",
        "print('maximum target index:', np.argmax(np.array(target_list)))"
      ],
      "metadata": {
        "id": "v7lNQiAITdQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_dict = lgbBO.res[np.argmax(np.array(target_list))]\n",
        "print(max_dict)"
      ],
      "metadata": {
        "id": "IIVNGr3wTeWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_apps_all(apps_all_train):\n",
        "\n",
        "    ftr_app = apps_all_train.drop(['TARGET'], axis=1)\n",
        "    target_app = apps_all_train['TARGET']\n",
        "\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(ftr_app, target_app, test_size=0.3, random_state=2020)\n",
        "    print('train shape:', train_x.shape, 'valid shape:', valid_x.shape)\n",
        "    clf = LGBMClassifier(\n",
        "                nthread=4,\n",
        "                n_estimators=1000,\n",
        "                learning_rate=0.02,\n",
        "                max_depth = 13,\n",
        "                num_leaves=57,\n",
        "                colsample_bytree=0.638,\n",
        "                subsample=0.682,\n",
        "                max_bin=435,\n",
        "                reg_alpha=0.936,\n",
        "                reg_lambda=4.533,\n",
        "                min_child_weight=25,\n",
        "                min_child_samples=166,\n",
        "                silent=-1,\n",
        "                verbose=-1,\n",
        "                )\n",
        "\n",
        "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 100,\n",
        "                early_stopping_rounds= 100)\n",
        "\n",
        "    return clf"
      ],
      "metadata": {
        "id": "4Nmq_Si8TgxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bayesian_params = {\n",
        "    'max_depth': (6, 16),\n",
        "    'num_leaves': (24, 64),\n",
        "    'min_data_in_leaf': (10, 200),\n",
        "    'min_child_weight':(1, 50),\n",
        "    'bagging_fraction':(0.5, 1.0),\n",
        "    'feature_fraction': (0.5, 1.0),\n",
        "    'max_bin':(10, 500),\n",
        "    'lambda_l2':(0.001, 10),\n",
        "    'lambda_l1': (0.01, 50)\n",
        "    }"
      ],
      "metadata": {
        "id": "iBJtZDhxT8eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "train_data = lgb.Dataset(data=ftr_app, label=target_app, free_raw_data=False)\n",
        "\n",
        "def lgb_roc_eval_cv(max_depth, num_leaves, min_data_in_leaf, min_child_weight, bagging_fraction,\n",
        "                 feature_fraction,  max_bin, lambda_l2, lambda_l1):\n",
        "    params = {\n",
        "        \"num_iterations\":500, \"learning_rate\":0.02,\n",
        "        'early_stopping_rounds':100, 'metric':'auc',\n",
        "        'max_depth': int(round(max_depth)),\n",
        "        'num_leaves': int(round(num_leaves)),\n",
        "        'min_data_in_leaf': int(round(min_data_in_leaf)),\n",
        "        'min_child_weight': int(round(min_child_weight)),\n",
        "        'bagging_fraction': max(min(bagging_fraction, 1), 0),\n",
        "        'feature_fraction': max(min(feature_fraction, 1), 0),\n",
        "        'max_bin':  max(int(round(max_bin)),10),\n",
        "        'lambda_l2': max(lambda_l2,0),\n",
        "        'lambda_l1': max(lambda_l1, 0)\n",
        "    }\n",
        "\n",
        "    cv_result = lgb.cv(params, train_data, nfold=3, seed=0,  verbose_eval =100,  early_stopping_rounds=50, metrics=['auc'])\n",
        "    return max(cv_result['auc-mean'])"
      ],
      "metadata": {
        "id": "-cevi8YoUCDZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}